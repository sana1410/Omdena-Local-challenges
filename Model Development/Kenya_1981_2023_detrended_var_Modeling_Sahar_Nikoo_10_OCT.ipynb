{"cells":[{"cell_type":"code","execution_count":null,"id":"e1ba3b31","metadata":{"id":"e1ba3b31"},"outputs":[],"source":["              # DataSet : Kenya_1981_2023_detrended_var"]},{"cell_type":"code","execution_count":null,"id":"36bfc229","metadata":{"id":"36bfc229"},"outputs":[],"source":["import pandas as pd\n","from scipy import stats\n","import numpy as np\n","import scipy\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline\n","import datetime\n","import plotly\n","import plotly.graph_objs as go\n","import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","import plotly.express as px\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"id":"5d7224f0","metadata":{"id":"5d7224f0"},"outputs":[],"source":["import statsmodels.formula.api as sm\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import FunctionTransformer\n","from sklearn.model_selection import train_test_split\n","from sklearn import preprocessing\n","from sklearn import tree\n","from sklearn.model_selection import cross_val_score"]},{"cell_type":"code","execution_count":null,"id":"cbYQ1rw9S-4e","metadata":{"id":"cbYQ1rw9S-4e"},"outputs":[],"source":["#!pip install catboost"]},{"cell_type":"code","execution_count":null,"id":"0940fbc9","metadata":{"id":"0940fbc9","colab":{"base_uri":"https://localhost:8080/","height":383},"outputId":"3ede3da9-fcc6-4790-ccdb-64dd9881fe58","executionInfo":{"status":"error","timestamp":1730113583233,"user_tz":-330,"elapsed":1786,"user":{"displayName":"amrutha vanaparthi","userId":"02511824872321336299"}}},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'catboost'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-5798abd5b5a2>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKNeighborsRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExtraTreesRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCatBoostRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catboost'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["# Import Regressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn.linear_model import LinearRegression,Lasso,Ridge,ElasticNet\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import AdaBoostRegressor\n","from sklearn.svm import SVR\n","import xgboost as xgb\n","from sklearn.linear_model import BayesianRidge\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.ensemble import ExtraTreesRegressor\n","# from catboost import CatBoostRegressor\n","import lightgbm as lgb\n","\n","#import the metrics\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"]},{"cell_type":"code","execution_count":null,"id":"534df1a3","metadata":{"id":"534df1a3"},"outputs":[],"source":["df = pd.read_csv('Kenya_1981_2023_detrended_var.csv')\n","df.head()"]},{"cell_type":"code","execution_count":null,"id":"81aaf756","metadata":{"id":"81aaf756"},"outputs":[],"source":["df.info()"]},{"cell_type":"code","execution_count":null,"id":"bd23fd37","metadata":{"id":"bd23fd37"},"outputs":[],"source":["df.shape"]},{"cell_type":"code","execution_count":null,"id":"424387a2","metadata":{"id":"424387a2"},"outputs":[],"source":["# Value counts for each categorical feature:\n","\n","for column in df.select_dtypes(include=['object']):\n","    print(f\"Value counts for {column}:\")\n","    print(df[column].value_counts())\n","    print(df[column].nunique())\n","    print(\"=\"*45)"]},{"cell_type":"code","execution_count":null,"id":"dcfb7aae","metadata":{"id":"dcfb7aae"},"outputs":[],"source":["# Check for missing values\n","missing_values = df.isnull().sum()\n","missing_values"]},{"cell_type":"code","execution_count":null,"id":"8e2e0865","metadata":{"id":"8e2e0865"},"outputs":[],"source":["df = df.drop(columns=[\"Unnamed: 0\", \"area\"])"]},{"cell_type":"markdown","id":"416da8a9","metadata":{"id":"416da8a9"},"source":["# Univariate Analysis - Histogram"]},{"cell_type":"code","execution_count":null,"id":"e86e82ea","metadata":{"id":"e86e82ea","scrolled":false},"outputs":[],"source":["for i in df.columns:\n","    plt.figure(figsize = (10,4))\n","    sns.histplot(df[i], kde=True)\n","    plt.xlabel(i)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"id":"ddb5b678","metadata":{"id":"ddb5b678"},"outputs":[],"source":["# Calculate skewness for all numerical columns\n","skewness = df.select_dtypes(include=['number']).skew()\n","\n","# Display the skewness values\n","print(skewness)"]},{"cell_type":"markdown","id":"c63f2634","metadata":{"id":"c63f2634"},"source":["# Outlier Detection"]},{"cell_type":"code","execution_count":null,"id":"0629178e","metadata":{"id":"0629178e"},"outputs":[],"source":["# Detecting outliers using IQR (Interquartile Range)\n","numeric_data = df.select_dtypes(include=['number'])\n","\n","# Calculate the first and third quartile\n","Q1 = numeric_data.quantile(0.25)\n","Q3 = numeric_data.quantile(0.75)\n","\n","# Calculate the interquartile range (IQR)\n","IQR = Q3 - Q1\n","\n","# Detect outliers\n","outliers = ((numeric_data < (Q1 - 1.5 * IQR)) | (numeric_data > (Q3 + 1.5 * IQR))).sum()\n","\n","print(outliers)"]},{"cell_type":"code","execution_count":null,"id":"bf4d763f","metadata":{"id":"bf4d763f"},"outputs":[],"source":["print(df.select_dtypes(include=['int64','float64']).columns)"]},{"cell_type":"markdown","id":"0287faf9","metadata":{"id":"0287faf9"},"source":["# Insight into 'yield_fao_1000ha' - Histogram Plot"]},{"cell_type":"code","execution_count":null,"id":"e333799a","metadata":{"id":"e333799a"},"outputs":[],"source":["plt.figure(figsize=(6, 4))\n","sns.histplot(data=df, x='yield_fao_1000ha', element='step', common_norm=False)\n","\n","\n","mean = np.mean(df['yield_fao_1000ha'])\n","median = np.median(df['yield_fao_1000ha'])\n","std_deviation = np.std(df['yield_fao_1000ha'])\n","\n","plt.axvline(mean, color='red', linestyle='--')\n","plt.axvline(median, color='blue', linestyle='--')\n","plt.axvline(x=std_deviation, color='green', linestyle='--')\n","\n","# annotate mean,median & Standard deviation\n","plt.annotate(f'Mean: {mean:.3}', xy=(mean, plt.gca().get_ylim()[1]), xytext=(85, -30),\n","             textcoords='offset points', color='red', fontsize=10)\n","plt.annotate(f'Median: {median:.3f}', xy=(median, plt.gca().get_ylim()[1]), xytext=(90, -50),\n","             textcoords='offset points', color='blue', fontsize=10)\n","plt.annotate(f'Standard deviation: {std_deviation:.3f}', xy=(std_deviation, plt.gca().get_ylim()[1]), xytext=(-50, -70),\n","           textcoords='offset points', color='green', fontsize=10)\n","plt.xlabel('yield_fao_1000ha')\n","plt.ylabel('Frequency')\n","plt.title('Distribution of yield_fao_1000ha')\n","plt.show()"]},{"cell_type":"markdown","id":"e74eaa75","metadata":{"id":"e74eaa75"},"source":["# Insight into 'yield_usda_1000ha' - Histogram Plot"]},{"cell_type":"code","execution_count":null,"id":"1d757ac6","metadata":{"id":"1d757ac6"},"outputs":[],"source":["plt.figure(figsize=(6, 4))\n","sns.histplot(data=df, x='yield_usda_1000ha', element='step', common_norm=False)\n","\n","\n","mean = np.mean(df['yield_usda_1000ha'])\n","median = np.median(df['yield_usda_1000ha'])\n","std_deviation = np.std(df['yield_usda_1000ha'])\n","\n","plt.axvline(mean, color='red', linestyle='--')\n","plt.axvline(median, color='blue', linestyle='--')\n","plt.axvline(x=std_deviation, color='green', linestyle='--')\n","\n","# annotate mean,median & Standard deviation\n","plt.annotate(f'Mean: {mean:.3}', xy=(mean, plt.gca().get_ylim()[1]), xytext=(-120, -30),\n","             textcoords='offset points', color='red', fontsize=10)\n","plt.annotate(f'Median: {median:.3f}', xy=(median, plt.gca().get_ylim()[1]), xytext=(-120, -50),\n","             textcoords='offset points', color='blue', fontsize=10)\n","plt.annotate(f'Standard deviation: {std_deviation:.3f}', xy=(std_deviation, plt.gca().get_ylim()[1]), xytext=(-210, -70),\n","           textcoords='offset points', color='green', fontsize=10)\n","plt.xlabel('yield_usda_1000ha')\n","plt.ylabel('Frequency')\n","plt.title('Distribution of yield_usda_1000ha')\n","plt.show()"]},{"cell_type":"markdown","id":"6ba442a8","metadata":{"id":"6ba442a8"},"source":["# Correlation Analysis"]},{"cell_type":"code","execution_count":null,"id":"9f03c08f","metadata":{"id":"9f03c08f"},"outputs":[],"source":["df_corr = df.corr(method='pearson')\n","df_corr= df_corr.applymap(\"{:.3f}\".format)\n","df_corr"]},{"cell_type":"code","execution_count":null,"id":"a69cc226","metadata":{"id":"a69cc226"},"outputs":[],"source":["# Correlation Matrix\n","correlation_matrix = df.corr()\n","plt.figure(figsize=(18, 16))\n","mask = np.triu(correlation_matrix)\n","sns.heatmap(correlation_matrix, annot=True, cmap='viridis_r', center=0, mask=mask, fmt=\".2f\")\n","plt.xticks(rotation = 90, fontsize=12)\n","plt.yticks(fontsize=12)\n","plt.title('Correlational Heatmap')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"5983b89f","metadata":{"id":"5983b89f"},"outputs":[],"source":["df_corr[\"yield_usda_1000ha\"].sort_values(ascending=False)"]},{"cell_type":"code","execution_count":null,"id":"379b5a07","metadata":{"id":"379b5a07"},"outputs":[],"source":["df_corr[\"yield_fao_1000ha\"].sort_values(ascending=False)"]},{"cell_type":"markdown","id":"e221eb69","metadata":{"id":"e221eb69"},"source":["# 1) Modeling - Target: \"yield_fao_1000ha\" - All Features"]},{"cell_type":"code","execution_count":null,"id":"2c227ef1","metadata":{"id":"2c227ef1"},"outputs":[],"source":["df.columns"]},{"cell_type":"code","execution_count":null,"id":"88a13adf","metadata":{"id":"88a13adf"},"outputs":[],"source":["# columns to exclude : 'year' , 'yield_usda_1000ha'\n","\n","num_var = ['area_harvested_usda_1000ha', 'production_usda_1000ha',\n","       'area_harvested_fao_1000ha',\n","       'production_fao_1000ha', 'dew_temp_C',\n","       'soil_temp_L1_C', 'soil_temp_L2_C', 'soil_temp_L3_C', 'soil_temp_L4_C',\n","       'irradiation_J_m2', 'temp_C', 'max_temp_C', 'min_temp_C',\n","       'evaporation_mm', 'precipitation_era5_mm', 'wind_eastward_m_s',\n","       'wind_northward_m_s', 'soil_water_L1_fraction',\n","       'soil_water_L2_fraction', 'soil_water_L3_fraction',\n","       'soil_water_L4_fraction', 'precipitation_chirps_mm']\n","\n","cat_var = []\n","\n","y = df['yield_fao_1000ha']\n","\n","X = df[cat_var + num_var]\n","y = pd.DataFrame(y, columns=['yield_fao_1000ha'])"]},{"cell_type":"code","execution_count":null,"id":"79d4f534","metadata":{"id":"79d4f534"},"outputs":[],"source":["print(type(X))\n","print(type(y))"]},{"cell_type":"code","execution_count":null,"id":"e0caad26","metadata":{"id":"e0caad26"},"outputs":[],"source":["X.info()"]},{"cell_type":"code","execution_count":null,"id":"77a47687","metadata":{"id":"77a47687"},"outputs":[],"source":["# Train-test split:\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42 , shuffle=True)\n","\n","print(f\"X_train.shape: {X_train.shape}\")\n","print(f\"X_test.shape: {X_test.shape}\")\n","print(f\"y_train.shape: {y_train.shape}\")\n","print(f\"y_test.shape: {y_test.shape}\")"]},{"cell_type":"code","execution_count":null,"id":"86f0322d","metadata":{"id":"86f0322d"},"outputs":[],"source":["# Preprocessing with pipelines\n","\n","from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n","\n","\n","pipeline_categorical = Pipeline([('onehot', OneHotEncoder(handle_unknown=\"ignore\")),])\n","\n","pipeline_numerical = Pipeline([('scaler', MinMaxScaler(feature_range=(0,1))),])\n","\n","pipeline_full = ColumnTransformer([(\"categorical\", pipeline_categorical, cat_var),\n","                                   (\"numerical\", pipeline_numerical, num_var)])"]},{"cell_type":"code","execution_count":null,"id":"2f64d6a7","metadata":{"id":"2f64d6a7"},"outputs":[],"source":["# Apply the pipeline\n","\n","pipeline_full.fit(X_train)\n","\n","X_train_transformed = pipeline_full.transform(X_train)\n","X_test_transformed = pipeline_full.transform(X_test)\n","\n","print(f\"X_train_transformed.shape: {X_train_transformed.shape}\")\n","print(f\"X_test_transformed.shape: {X_test_transformed.shape}\")\n","print()\n","print('X_train_transformed:', type(X_train_transformed))\n","print('X_test_transformed:', type(X_test_transformed))"]},{"cell_type":"code","execution_count":null,"id":"59942f61","metadata":{"id":"59942f61"},"outputs":[],"source":["models = {\n","    'LinearRegression': LinearRegression(),\n","    'LassoRegressor': Lasso(max_iter=10000, random_state=42),\n","    'RidgeRegressor': Ridge(max_iter=10000, random_state=42),\n","    \"ElasticNet\": ElasticNet(alpha=0.02, random_state=42),\n","    # \"KNN\": KNeighborsRegressor(),\n","    'DTR': DecisionTreeRegressor(random_state=42),\n","    'SVR': SVR(),\n","    'RFR': RandomForestRegressor(random_state=42),\n","    \"ExtraTrees\": ExtraTreesRegressor(n_estimators=5, random_state=42),\n","    'ADABoost': AdaBoostRegressor(random_state=42),\n","    'XGBoost': xgb.XGBRegressor(random_state=42),\n","    'CatBoost': CatBoostRegressor(random_state=42),\n","    'LightGBM': lgb.LGBMRegressor(random_state=42)\n","}"]},{"cell_type":"code","execution_count":null,"id":"bfbf0652","metadata":{"id":"bfbf0652","scrolled":false},"outputs":[],"source":["# Train multiple models\n","\n","model_list=[]\n","r2_list=[]\n","mae_list=[]\n","mse_list=[]\n","rmse_list=[]\n","\n","for i in range(len(list(models))):\n","    model=list(models.values())[i]\n","    model.fit(X_train_transformed,y_train)\n","\n","    #Make Predictions\n","    y_pred=model.predict(X_test_transformed)\n","\n","    # Evaluation Metric:\n","    #r2 = model.score(X_test_transformed, y_test)\n","    r2 = r2_score(y_test, y_pred)\n","    mae = mean_absolute_error(y_test, y_pred)\n","    mse = mean_squared_error(y_test, y_pred)\n","    rmse= np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    model_list.append(list(models.keys())[i])\n","    r2_list.append(r2)\n","    mae_list.append(mae)\n","    mse_list.append(mse)\n","    rmse_list.append(rmse)\n","\n","    # Print the performance metrics for each model\n","    print(f\"Model: {list(models.keys())[i]}\")\n","    print(f\"R2 Score: {r2}\")\n","    print(f\"MAE: {mae}\")\n","    print(f\"MSE: {mse}\")\n","    print(f\"RMSE: {rmse}\")\n","    print(\"=\"*30)"]},{"cell_type":"code","execution_count":null,"id":"d01f77cc","metadata":{"id":"d01f77cc"},"outputs":[],"source":["# Find the index of the model with the best r2 score\n","best_index_r2 = r2_list.index(max(r2_list))\n","\n","# Find the index of the model with the best mae score\n","best_index_mae = mae_list.index(min(mae_list))\n","\n","# Find the index of the model with the best mse score\n","best_index_mse = mse_list.index(min(mse_list))\n","\n","# Find the index of the model with the best rmse score\n","best_index_rmse = rmse_list.index(min(rmse_list))\n","\n","# Determine the model with the best performance based on the chosen metric\n","best_r2_model = model_list[best_index_r2]\n","best_mae_model = model_list[best_index_mae]\n","best_mse_model = model_list[best_index_mse]\n","best_rmse_model = model_list[best_index_rmse]\n","\n","# Print the best models and their corresponding metric\n","print(\"The model with the best R2 score is:\", best_r2_model)\n","print(\"R2 score:\", r2_list[best_index_r2])\n","print(\"=\"*40)\n","print(\"The model with the best MAE score is:\", best_mae_model)\n","print(\"MAE:\", mae_list[best_index_mae])\n","print(\"=\"*40)\n","print(\"The model with the best MSE score is:\", best_mse_model)\n","print(\"MSE:\", mse_list[best_index_mse])\n","print(\"=\"*40)\n","print(\"The model with the best RMSE score is:\", best_rmse_model)\n","print(\"RMSE:\", rmse_list[best_index_rmse])"]},{"cell_type":"code","execution_count":null,"id":"C_sOmgQhYsCx","metadata":{"id":"C_sOmgQhYsCx"},"outputs":[],"source":["# Create a DF for Result:\n","\n","results_df = pd.DataFrame({\n","    'Model': model_list,\n","    'R2 Score': r2_list,\n","    'MAE': mae_list,\n","    'MSE': mse_list,\n","    'RMSE': rmse_list})\n","\n","results_df.sort_values(by=\"RMSE\", ascending=True)"]},{"cell_type":"markdown","id":"3ec00b61","metadata":{"id":"3ec00b61"},"source":["# **First Top Model: Ridge Regressor**"]},{"cell_type":"markdown","id":"8112ee55","metadata":{"id":"8112ee55"},"source":["**Hyperparameter Search for Ridge Regression:**"]},{"cell_type":"code","execution_count":null,"id":"50550b64","metadata":{"id":"50550b64"},"outputs":[],"source":["# Hyperparameter Search for Ridge Regression:\n","\n","from sklearn.linear_model import Ridge\n","from sklearn.model_selection import GridSearchCV\n","\n","param_grid = {\n","    'alpha': [0.01, 0.1, 1.0, 10.0],\n","    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']}\n","\n","grid_search = GridSearchCV(\n","    estimator=Ridge(),\n","    param_grid=param_grid,\n","    scoring='neg_mean_squared_error',\n","    cv=5, n_jobs=-1, verbose=1)\n","\n","grid_search.fit(X_train_transformed, y_train)\n"]},{"cell_type":"code","execution_count":null,"id":"30a5699b","metadata":{"id":"30a5699b"},"outputs":[],"source":["print(grid_search.best_params_)\n","print(\"\\n\",grid_search.best_estimator_)"]},{"cell_type":"code","execution_count":null,"id":"d1334602","metadata":{"id":"d1334602"},"outputs":[],"source":["Tuned_Ridge_Reg = grid_search.best_estimator_\n","Tuned_Ridge_Reg"]},{"cell_type":"code","execution_count":null,"id":"da636ca3","metadata":{"id":"da636ca3"},"outputs":[],"source":["Tuned_Ridge_Reg .fit(X_train_transformed,y_train)\n","y_pred=Tuned_Ridge_Reg.predict(X_test_transformed)"]},{"cell_type":"code","execution_count":null,"id":"78153f14","metadata":{"id":"78153f14"},"outputs":[],"source":["from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n","\n","r2 = r2_score(y_test, y_pred)\n","mae = mean_absolute_error(y_test, y_pred)\n","mse = mean_squared_error(y_test, y_pred)\n","rmse = np.sqrt(mse)\n","\n","print(f\"R2 Score: {r2}\")\n","print(f\"MAE: {mse}\")\n","print(f\"MSE: {mae}\")\n","print(f\"RMSE: {rmse}\")"]},{"cell_type":"code","execution_count":null,"id":"eb1c7559","metadata":{"id":"eb1c7559"},"outputs":[],"source":["# Calculate residuals\n","residuals = y_test.values.flatten() - y_pred.flatten()\n","\n","# Visualize residuals\n","#sns.kdeplot(residuals)\n","sns.histplot(residuals, kde=True)\n","plt.title('Distribution of Residuals - Tuned Ridge Regression')\n","plt.xlabel('Residuals')\n","plt.ylabel('Density')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"f801d50c","metadata":{"id":"f801d50c","scrolled":false},"outputs":[],"source":["# Line Plot: Actual vs Predicted Values\n","\n","plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--', color='green', label='Actual')\n","plt.scatter(y_test, y_pred, label='Tuned Ridge Regression Predictions')\n","plt.xlabel('Actual Values')\n","plt.ylabel('Predicted Values')\n","plt.title('Actual vs Predicted Values - Tuned Ridge Regression')\n","plt.show()"]},{"cell_type":"markdown","id":"3d48aa72","metadata":{"id":"3d48aa72"},"source":["**Ploting the Learning Curve**"]},{"cell_type":"code","execution_count":null,"id":"2bff1014","metadata":{"scrolled":false,"id":"2bff1014"},"outputs":[],"source":["# Ploting the learning curve:\n","\n","from sklearn.model_selection import learning_curve\n","train_sizes, train_scores, test_scores = learning_curve(estimator=Tuned_Ridge_Reg, X=X_train_transformed, y=y_train,\n","                                                       cv=5, train_sizes=np.linspace(0.1, 1.0, 20), n_jobs=-1)\n","\n","plt.figure(figsize=(8,4))\n","# Calculate training and test mean and std\n","\n","train_mean = np.mean(train_scores, axis=1)\n","train_std = np.std(train_scores, axis=1)\n","test_mean = np.mean(test_scores, axis=1)\n","test_std = np.std(test_scores, axis=1)\n","\n","# Plot the learning curve\n","\n","plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='Training Score')\n","plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n","\n","plt.plot(train_sizes, test_mean, color='green', marker='o', markersize=5, label='Cross-Validation Score')\n","plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n","\n","plt.title('Tuned Ridge Regression Learning Curve ')\n","plt.xlabel('Training Example', fontsize=12)\n","plt.ylabel('Accuracy Score', fontsize=12)\n","\n","plt.legend(loc='lower center', fontsize=8)\n","plt.show()\n"]},{"cell_type":"markdown","id":"c1592fc1","metadata":{"id":"c1592fc1"},"source":["# Forward Feature Selection"]},{"cell_type":"code","execution_count":null,"id":"9ad74792","metadata":{"id":"9ad74792"},"outputs":[],"source":["from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n","\n","# Perform forward feature selection\n","sfs_forward = SFS(Tuned_Ridge_Reg,\n","                  k_features='best',\n","                  forward=True,\n","                  floating=False,\n","                  scoring='neg_mean_squared_error',\n","                  cv=5)\n","\n","sfs_forward.fit(X_train_transformed, y_train.values.ravel())\n","\n","# Selected features using forward selection\n","selected_features_forward_indices = sfs_forward.k_feature_idx_\n","selected_features_forward_names = [num_var[i] for i in selected_features_forward_indices]\n","print(f'Selected features (Forward): {selected_features_forward_names}')"]},{"cell_type":"markdown","id":"7931d3bb","metadata":{"id":"7931d3bb"},"source":["# Modeling - Target : 'yield_fao_1000ha' - Selected Features"]},{"cell_type":"code","execution_count":null,"id":"a060df6d","metadata":{"id":"a060df6d"},"outputs":[],"source":["num_var = ['area_harvested_usda_1000ha',\n"," 'area_harvested_fao_1000ha',\n"," 'production_fao_1000ha',\n"," 'soil_temp_L3_C',\n"," 'temp_C',\n"," 'max_temp_C',\n"," 'min_temp_C',\n"," 'evaporation_mm',\n"," 'wind_eastward_m_s',\n"," 'soil_water_L1_fraction',\n"," 'precipitation_chirps_mm']\n","\n","\n","cat_var = []\n","\n","y = df['yield_fao_1000ha']\n","\n","X = df[cat_var + num_var]\n","y = pd.DataFrame(y, columns=['yield_fao_1000ha'])"]},{"cell_type":"code","execution_count":null,"id":"bf39525f","metadata":{"id":"bf39525f"},"outputs":[],"source":["X.info()"]},{"cell_type":"code","execution_count":null,"id":"d69e839a","metadata":{"id":"d69e839a"},"outputs":[],"source":["# Train-test split:\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42 , shuffle=True)\n","\n","print(f\"X_train.shape: {X_train.shape}\")\n","print(f\"X_test.shape: {X_test.shape}\")\n","print(f\"y_train.shape: {y_train.shape}\")\n","print(f\"y_test.shape: {y_test.shape}\")"]},{"cell_type":"code","execution_count":null,"id":"913133d6","metadata":{"id":"913133d6"},"outputs":[],"source":["# Preprocessing with pipelines\n","\n","from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n","\n","\n","pipeline_categorical = Pipeline([('onehot', OneHotEncoder(handle_unknown=\"ignore\")),])\n","\n","pipeline_numerical = Pipeline([('scaler', MinMaxScaler(feature_range=(0,1))),])\n","\n","pipeline_full = ColumnTransformer([(\"categorical\", pipeline_categorical, cat_var),\n","                                   (\"numerical\", pipeline_numerical, num_var)])"]},{"cell_type":"code","execution_count":null,"id":"4671bee2","metadata":{"id":"4671bee2"},"outputs":[],"source":["# Apply the pipeline\n","\n","pipeline_full.fit(X_train)\n","\n","X_train_transformed = pipeline_full.transform(X_train)\n","X_test_transformed = pipeline_full.transform(X_test)\n","\n","print(f\"X_train_transformed.shape: {X_train_transformed.shape}\")\n","print(f\"X_test_transformed.shape: {X_test_transformed.shape}\")\n","print()\n","print('X_train_transformed:', type(X_train_transformed))\n","print('X_test_transformed:', type(X_test_transformed))"]},{"cell_type":"code","execution_count":null,"id":"4a5894bb","metadata":{"id":"4a5894bb"},"outputs":[],"source":["models = {\n","    'LinearRegression': LinearRegression(),\n","    'LassoRegressor': Lasso(max_iter=10000, random_state=42),\n","    'RidgeRegressor': Ridge(max_iter=10000, random_state=42),\n","    \"ElasticNet\": ElasticNet(alpha=0.02, random_state=42),\n","    # \"KNN\": KNeighborsRegressor(),\n","    'DTR': DecisionTreeRegressor(random_state=42),\n","    'SVR': SVR(),\n","    'RFR': RandomForestRegressor(random_state=42),\n","    \"ExtraTrees\": ExtraTreesRegressor(n_estimators=5, random_state=42),\n","    'ADABoost': AdaBoostRegressor(random_state=42),\n","    'XGBoost': xgb.XGBRegressor(random_state=42),\n","    'CatBoost': CatBoostRegressor(random_state=42),\n","    'LightGBM': lgb.LGBMRegressor(random_state=42)\n","}"]},{"cell_type":"code","execution_count":null,"id":"9d8ba18c","metadata":{"id":"9d8ba18c","scrolled":false},"outputs":[],"source":["# Train multiple models\n","\n","model_list=[]\n","r2_list=[]\n","mae_list=[]\n","mse_list=[]\n","rmse_list=[]\n","\n","for i in range(len(list(models))):\n","    model=list(models.values())[i]\n","    model.fit(X_train_transformed,y_train)\n","\n","    #Make Predictions\n","    y_pred=model.predict(X_test_transformed)\n","\n","    # Evaluation Metric:\n","    #r2 = model.score(X_test_transformed, y_test)\n","    r2 = r2_score(y_test, y_pred)\n","    mae = mean_absolute_error(y_test, y_pred)\n","    mse = mean_squared_error(y_test, y_pred)\n","    rmse= np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    model_list.append(list(models.keys())[i])\n","    r2_list.append(r2)\n","    mae_list.append(mae)\n","    mse_list.append(mse)\n","    rmse_list.append(rmse)\n","\n","    # Print the performance metrics for each model\n","    print(f\"Model: {list(models.keys())[i]}\")\n","    print(f\"R2 Score: {r2}\")\n","    print(f\"MAE: {mae}\")\n","    print(f\"MSE: {mse}\")\n","    print(f\"RMSE: {rmse}\")\n","    print(\"=\"*30)"]},{"cell_type":"code","execution_count":null,"id":"dc4562b0","metadata":{"id":"dc4562b0"},"outputs":[],"source":["# Find the index of the model with the best r2 score\n","best_index_r2 = r2_list.index(max(r2_list))\n","\n","# Find the index of the model with the best mae score\n","best_index_mae = mae_list.index(min(mae_list))\n","\n","# Find the index of the model with the best mse score\n","best_index_mse = mse_list.index(min(mse_list))\n","\n","# Find the index of the model with the best rmse score\n","best_index_rmse = rmse_list.index(min(rmse_list))\n","\n","# Determine the model with the best performance based on the chosen metric\n","best_r2_model = model_list[best_index_r2]\n","best_mae_model = model_list[best_index_mae]\n","best_mse_model = model_list[best_index_mse]\n","best_rmse_model = model_list[best_index_rmse]\n","\n","# Print the best models and their corresponding metric\n","print(\"The model with the best R2 score is:\", best_r2_model)\n","print(\"R2 score:\", r2_list[best_index_r2])\n","print(\"=\"*40)\n","print(\"The model with the best MAE score is:\", best_mae_model)\n","print(\"MAE:\", mae_list[best_index_mae])\n","print(\"=\"*40)\n","print(\"The model with the best MSE score is:\", best_mse_model)\n","print(\"MSE:\", mse_list[best_index_mse])\n","print(\"=\"*40)\n","print(\"The model with the best RMSE score is:\", best_rmse_model)\n","print(\"RMSE:\", rmse_list[best_index_rmse])"]},{"cell_type":"code","execution_count":null,"id":"ade22acc","metadata":{"id":"ade22acc"},"outputs":[],"source":["# Create a DF for Result:\n","\n","results_df = pd.DataFrame({\n","    'Model': model_list,\n","    'R2 Score': r2_list,\n","    'MAE': mae_list,\n","    'MSE': mse_list,\n","    'RMSE': rmse_list})\n","\n","results_df.sort_values(by=\"RMSE\", ascending=True)"]},{"cell_type":"markdown","id":"9b840862","metadata":{"id":"9b840862"},"source":["# First Top Model: Ridge Regressor"]},{"cell_type":"markdown","id":"8a713043","metadata":{"id":"8a713043"},"source":["**Hyperparameter Search for Ridge Regression:**"]},{"cell_type":"code","execution_count":null,"id":"95f322a1","metadata":{"id":"95f322a1"},"outputs":[],"source":["# Hyperparameter Search for Ridge Regression:\n","\n","from sklearn.linear_model import Ridge\n","from sklearn.model_selection import GridSearchCV\n","\n","param_grid = {\n","    'alpha': [0.01, 0.1, 1.0, 10.0],\n","    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']}\n","\n","grid_search = GridSearchCV(\n","    estimator=Ridge(),\n","    param_grid=param_grid,\n","    scoring='neg_mean_squared_error',\n","    cv=5, n_jobs=-1, verbose=1)\n","\n","grid_search.fit(X_train_transformed, y_train)\n"]},{"cell_type":"code","execution_count":null,"id":"f0a69995","metadata":{"id":"f0a69995"},"outputs":[],"source":["print(grid_search.best_params_)\n","print(\"\\n\",grid_search.best_estimator_)"]},{"cell_type":"code","execution_count":null,"id":"59ef85c3","metadata":{"id":"59ef85c3"},"outputs":[],"source":["Tuned_Ridge_Reg = grid_search.best_estimator_\n","Tuned_Ridge_Reg"]},{"cell_type":"code","execution_count":null,"id":"77ce0f23","metadata":{"id":"77ce0f23"},"outputs":[],"source":["Tuned_Ridge_Reg .fit(X_train_transformed,y_train)\n","y_pred=Tuned_Ridge_Reg.predict(X_test_transformed)"]},{"cell_type":"code","execution_count":null,"id":"4f245fea","metadata":{"id":"4f245fea"},"outputs":[],"source":["from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n","\n","r2 = r2_score(y_test, y_pred)\n","mae = mean_absolute_error(y_test, y_pred)\n","mse = mean_squared_error(y_test, y_pred)\n","rmse = np.sqrt(mse)\n","\n","print(f\"R2 Score: {r2}\")\n","print(f\"MAE: {mse}\")\n","print(f\"MSE: {mae}\")\n","print(f\"RMSE: {rmse}\")"]},{"cell_type":"code","execution_count":null,"id":"b36793ae","metadata":{"id":"b36793ae"},"outputs":[],"source":["# Calculate residuals\n","residuals = y_test.values.flatten() - y_pred.flatten()\n","\n","# Visualize residuals\n","#sns.kdeplot(residuals)\n","sns.histplot(residuals, kde=True)\n","plt.title('Distribution of Residuals - Tuned Ridge Regression')\n","plt.xlabel('Residuals')\n","plt.ylabel('Density')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"56ce25c5","metadata":{"id":"56ce25c5","scrolled":false},"outputs":[],"source":["# Line Plot: Actual vs Predicted Values\n","\n","plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--', color='green', label='Actual')\n","plt.scatter(y_test, y_pred, label='Tuned Ridge Regression Predictions')\n","plt.xlabel('Actual Values')\n","plt.ylabel('Predicted Values')\n","plt.title('Actual vs Predicted Values - Tuned Ridge Regression')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"c8a9dc89","metadata":{"id":"c8a9dc89"},"outputs":[],"source":["# Ploting the learning curve:\n","\n","from sklearn.model_selection import learning_curve\n","train_sizes, train_scores, test_scores = learning_curve(estimator=Tuned_Ridge_Reg, X=X_train_transformed, y=y_train,\n","                                                       cv=5, train_sizes=np.linspace(0.1, 1.0, 20), n_jobs=-1)\n","\n","plt.figure(figsize=(8,4))\n","# Calculate training and test mean and std\n","\n","train_mean = np.mean(train_scores, axis=1)\n","train_std = np.std(train_scores, axis=1)\n","test_mean = np.mean(test_scores, axis=1)\n","test_std = np.std(test_scores, axis=1)\n","\n","# Plot the learning curve\n","\n","plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='Training Score')\n","plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n","\n","plt.plot(train_sizes, test_mean, color='green', marker='o', markersize=5, label='Cross-Validation Score')\n","plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n","\n","plt.title('Tuned Ridge Regression Learning Curve ')\n","plt.xlabel('Training Example', fontsize=12)\n","plt.ylabel('Accuracy Score', fontsize=12)\n","\n","plt.legend(loc='lower center', fontsize=8)\n","plt.show()\n"]},{"cell_type":"markdown","id":"a6c9abb3","metadata":{"id":"a6c9abb3"},"source":["# 2) Modeling - Target: \"yield_usda_1000ha\" - All Features"]},{"cell_type":"code","execution_count":null,"id":"191a871f","metadata":{"id":"191a871f"},"outputs":[],"source":["df.columns"]},{"cell_type":"code","execution_count":null,"id":"f7377143","metadata":{"id":"f7377143"},"outputs":[],"source":["# Columns to exclude = \"year\", 'yield_fao_1000ha'\n","\n","num_var = ['area_harvested_usda_1000ha', 'production_usda_1000ha',\n","        'area_harvested_fao_1000ha',\n","       'production_fao_1000ha', 'dew_temp_C',\n","       'soil_temp_L1_C', 'soil_temp_L2_C', 'soil_temp_L3_C', 'soil_temp_L4_C',\n","       'irradiation_J_m2', 'temp_C', 'max_temp_C', 'min_temp_C',\n","       'evaporation_mm', 'precipitation_era5_mm', 'wind_eastward_m_s',\n","       'wind_northward_m_s', 'soil_water_L1_fraction',\n","       'soil_water_L2_fraction', 'soil_water_L3_fraction',\n","       'soil_water_L4_fraction', 'precipitation_chirps_mm']\n","\n","cat_var = []\n","\n","y = df['yield_usda_1000ha']\n","\n","X = df[cat_var + num_var]\n","y = pd.DataFrame(y, columns=['yield_usda_1000ha'])"]},{"cell_type":"code","execution_count":null,"id":"b34b609a","metadata":{"id":"b34b609a"},"outputs":[],"source":["print(type(X))\n","print(type(y))"]},{"cell_type":"code","execution_count":null,"id":"4312b23e","metadata":{"id":"4312b23e"},"outputs":[],"source":["X.info()"]},{"cell_type":"code","execution_count":null,"id":"32ca8b14","metadata":{"id":"32ca8b14"},"outputs":[],"source":["# Train-test split:\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42 , shuffle=True)\n","\n","print(f\"X_train.shape: {X_train.shape}\")\n","print(f\"X_test.shape: {X_test.shape}\")\n","print(f\"y_train.shape: {y_train.shape}\")\n","print(f\"y_test.shape: {y_test.shape}\")"]},{"cell_type":"code","execution_count":null,"id":"b4cc795b","metadata":{"id":"b4cc795b"},"outputs":[],"source":["# Preprocessing with pipelines\n","\n","from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n","\n","\n","pipeline_categorical = Pipeline([('onehot', OneHotEncoder(handle_unknown=\"ignore\")),])\n","\n","pipeline_numerical = Pipeline([('scaler', MinMaxScaler(feature_range=(0,1))),])\n","\n","pipeline_full = ColumnTransformer([(\"categorical\", pipeline_categorical, cat_var),\n","                                   (\"numerical\", pipeline_numerical, num_var)])"]},{"cell_type":"code","execution_count":null,"id":"f0b22aa1","metadata":{"id":"f0b22aa1"},"outputs":[],"source":["# Apply the pipeline\n","\n","pipeline_full.fit(X_train)\n","\n","X_train_transformed = pipeline_full.transform(X_train)\n","X_test_transformed = pipeline_full.transform(X_test)\n","\n","print(f\"X_train_transformed.shape: {X_train_transformed.shape}\")\n","print(f\"X_test_transformed.shape: {X_test_transformed.shape}\")\n","print()\n","print('X_train_transformed:', type(X_train_transformed))\n","print('X_test_transformed:', type(X_test_transformed))"]},{"cell_type":"code","execution_count":null,"id":"c127e815","metadata":{"id":"c127e815"},"outputs":[],"source":["models = {\n","    'LinearRegression': LinearRegression(),\n","    'LassoRegressor': Lasso(max_iter=10000, random_state=42),\n","    'RidgeRegressor': Ridge(max_iter=10000, random_state=42),\n","    \"ElasticNet\": ElasticNet(alpha=0.02, random_state=42),\n","    # \"KNN\": KNeighborsRegressor(),\n","    'DTR': DecisionTreeRegressor(random_state=42),\n","    'SVR': SVR(),\n","    'RFR': RandomForestRegressor(random_state=42),\n","    \"ExtraTrees\": ExtraTreesRegressor(n_estimators=5, random_state=42),\n","    'ADABoost': AdaBoostRegressor(random_state=42),\n","    'XGBoost': xgb.XGBRegressor(random_state=42),\n","    'CatBoost': CatBoostRegressor(random_state=42),\n","    'LightGBM': lgb.LGBMRegressor(random_state=42)\n","}"]},{"cell_type":"code","execution_count":null,"id":"ab9fc48a","metadata":{"id":"ab9fc48a","scrolled":false},"outputs":[],"source":["# Train multiple models\n","\n","model_list=[]\n","r2_list=[]\n","mae_list=[]\n","mse_list=[]\n","rmse_list=[]\n","\n","for i in range(len(list(models))):\n","    model=list(models.values())[i]\n","    model.fit(X_train_transformed,y_train)\n","\n","    #Make Predictions\n","    y_pred=model.predict(X_test_transformed)\n","\n","    # Evaluation Metric:\n","    #r2 = model.score(X_test_transformed, y_test)\n","    r2 = r2_score(y_test, y_pred)\n","    mae = mean_absolute_error(y_test, y_pred)\n","    mse = mean_squared_error(y_test, y_pred)\n","    rmse= np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    model_list.append(list(models.keys())[i])\n","    r2_list.append(r2)\n","    mae_list.append(mae)\n","    mse_list.append(mse)\n","    rmse_list.append(rmse)\n","\n","    # Print the performance metrics for each model\n","    print(f\"Model: {list(models.keys())[i]}\")\n","    print(f\"R2 Score: {r2}\")\n","    print(f\"MAE: {mae}\")\n","    print(f\"MSE: {mse}\")\n","    print(f\"RMSE: {rmse}\")\n","    print(\"=\"*30)"]},{"cell_type":"code","execution_count":null,"id":"551e920e","metadata":{"id":"551e920e"},"outputs":[],"source":["# Find the index of the model with the best r2 score\n","best_index_r2 = r2_list.index(max(r2_list))\n","\n","# Find the index of the model with the best mae score\n","best_index_mae = mae_list.index(min(mae_list))\n","\n","# Find the index of the model with the best mse score\n","best_index_mse = mse_list.index(min(mse_list))\n","\n","# Find the index of the model with the best rmse score\n","best_index_rmse = rmse_list.index(min(rmse_list))\n","\n","# Determine the model with the best performance based on the chosen metric\n","best_r2_model = model_list[best_index_r2]\n","best_mae_model = model_list[best_index_mae]\n","best_mse_model = model_list[best_index_mse]\n","best_rmse_model = model_list[best_index_rmse]\n","\n","# Print the best models and their corresponding metric\n","print(\"The model with the best R2 score is:\", best_r2_model)\n","print(\"R2 score:\", r2_list[best_index_r2])\n","print(\"=\"*40)\n","print(\"The model with the best MAE score is:\", best_mae_model)\n","print(\"MAE:\", mae_list[best_index_mae])\n","print(\"=\"*40)\n","print(\"The model with the best MSE score is:\", best_mse_model)\n","print(\"MSE:\", mse_list[best_index_mse])\n","print(\"=\"*40)\n","print(\"The model with the best RMSE score is:\", best_rmse_model)\n","print(\"RMSE:\", rmse_list[best_index_rmse])"]},{"cell_type":"code","execution_count":null,"id":"ec4b1c03","metadata":{"id":"ec4b1c03"},"outputs":[],"source":["# Create a DF for Result:\n","\n","results_df = pd.DataFrame({\n","    'Model': model_list,\n","    'R2 Score': r2_list,\n","    'MAE': mae_list,\n","    'MSE': mse_list,\n","    'RMSE': rmse_list})\n","\n","results_df.sort_values(by=\"RMSE\", ascending=True)"]},{"cell_type":"markdown","id":"b1d6eaee","metadata":{"id":"b1d6eaee"},"source":["# Second Top Model: Ridge Regressor"]},{"cell_type":"markdown","id":"181b4703","metadata":{"id":"181b4703"},"source":["**Hyperparameter Search for Ridge Regression:**"]},{"cell_type":"code","execution_count":null,"id":"c5a26bfd","metadata":{"id":"c5a26bfd"},"outputs":[],"source":["# Hyperparameter Search for Ridge Regression:\n","\n","from sklearn.linear_model import Ridge\n","from sklearn.model_selection import GridSearchCV\n","\n","param_grid = {\n","    'alpha': [0.01, 0.1, 1.0, 10.0],\n","    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']}\n","\n","grid_search = GridSearchCV(\n","    estimator=Ridge(),\n","    param_grid=param_grid,\n","    scoring='neg_mean_squared_error',\n","    cv=5, n_jobs=-1, verbose=1)\n","\n","grid_search.fit(X_train_transformed, y_train)\n"]},{"cell_type":"code","execution_count":null,"id":"c766d27c","metadata":{"id":"c766d27c"},"outputs":[],"source":["print(grid_search.best_params_)\n","print(\"\\n\",grid_search.best_estimator_)"]},{"cell_type":"code","execution_count":null,"id":"e3e9a4a5","metadata":{"id":"e3e9a4a5"},"outputs":[],"source":["Tuned_Ridge_Reg = grid_search.best_estimator_\n","Tuned_Ridge_Reg"]},{"cell_type":"code","execution_count":null,"id":"38246512","metadata":{"id":"38246512"},"outputs":[],"source":["Tuned_Ridge_Reg .fit(X_train_transformed,y_train)\n","y_pred=Tuned_Ridge_Reg.predict(X_test_transformed)"]},{"cell_type":"code","execution_count":null,"id":"3791c823","metadata":{"id":"3791c823"},"outputs":[],"source":["from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n","\n","r2 = r2_score(y_test, y_pred)\n","mae = mean_absolute_error(y_test, y_pred)\n","mse = mean_squared_error(y_test, y_pred)\n","rmse = np.sqrt(mse)\n","\n","print(f\"R2 Score: {r2}\")\n","print(f\"MAE: {mse}\")\n","print(f\"MSE: {mae}\")\n","print(f\"RMSE: {rmse}\")"]},{"cell_type":"code","execution_count":null,"id":"53e048aa","metadata":{"id":"53e048aa","scrolled":false},"outputs":[],"source":["# Calculate residuals\n","residuals = y_test.values.flatten() - y_pred.flatten()\n","\n","# Visualize residuals\n","#sns.kdeplot(residuals)\n","sns.histplot(residuals, kde=True)\n","plt.title('Distribution of Residuals - Tuned Ridge Regression')\n","plt.xlabel('Residuals')\n","plt.ylabel('Density')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"964d337e","metadata":{"id":"964d337e","scrolled":false},"outputs":[],"source":["# Line Plot: Actual vs Predicted Values\n","\n","plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--', color='green', label='Actual')\n","plt.scatter(y_test, y_pred, label='Linear Regression Predictions')\n","plt.xlabel('Actual Values')\n","plt.ylabel('Predicted Values')\n","plt.title('Actual vs Predicted Values - Tuned Ridge Regression')\n","plt.show()"]},{"cell_type":"markdown","id":"f61581bb","metadata":{"id":"f61581bb"},"source":["**Ploting the Learning Curve**"]},{"cell_type":"code","execution_count":null,"id":"e2ff36f3","metadata":{"scrolled":false,"id":"e2ff36f3"},"outputs":[],"source":["# Ploting the learning curve:\n","\n","from sklearn.model_selection import learning_curve\n","train_sizes, train_scores, test_scores = learning_curve(estimator=Tuned_Ridge_Reg,\n","                                                       X=X_train_transformed, y=y_train,\n","                                                       cv=5, train_sizes=np.linspace(0.1, 1.0, 20), n_jobs=-1)\n","\n","plt.figure(figsize=(8,4))\n","# Calculate training and test mean and std\n","\n","train_mean = np.mean(train_scores, axis=1)\n","train_std = np.std(train_scores, axis=1)\n","test_mean = np.mean(test_scores, axis=1)\n","test_std = np.std(test_scores, axis=1)\n","\n","# Plot the learning curve\n","\n","plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='Training Score')\n","plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n","\n","plt.plot(train_sizes, test_mean, color='green', marker='o', markersize=5, label='Cross-Validation Score')\n","plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n","\n","plt.title('Tuned Ridge Regression Learning Curve ')\n","plt.xlabel('Training Example', fontsize=12)\n","plt.ylabel('Accuracy Score', fontsize=12)\n","\n","plt.legend(loc='lower center', fontsize=8)\n","plt.show()\n"]},{"cell_type":"markdown","id":"5c0eef62","metadata":{"id":"5c0eef62"},"source":["# Forward Feature Selection"]},{"cell_type":"code","execution_count":null,"id":"98d0e5c6","metadata":{"id":"98d0e5c6"},"outputs":[],"source":["from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n","\n","# Perform forward feature selection\n","sfs_forward = SFS(Tuned_Ridge_Reg,\n","                  k_features='best',\n","                  forward=True,\n","                  floating=False,\n","                  scoring='neg_mean_squared_error',\n","                  cv=5)\n","\n","sfs_forward.fit(X_train_transformed, y_train.values.ravel())\n","\n","# Selected features using forward selection\n","selected_features_forward_indices = sfs_forward.k_feature_idx_\n","selected_features_forward_names = [num_var[i] for i in selected_features_forward_indices]\n","print(f'Selected features (Forward): {selected_features_forward_names}')"]},{"cell_type":"markdown","id":"d7439a3e","metadata":{"id":"d7439a3e"},"source":["# Modeling - Target : 'yield_usda_1000ha' - Selected Features"]},{"cell_type":"code","execution_count":null,"id":"fc7c2d6f","metadata":{"id":"fc7c2d6f"},"outputs":[],"source":["num_var = ['area_harvested_usda_1000ha', 'production_usda_1000ha',\n","           'area_harvested_fao_1000ha', 'production_fao_1000ha',\n","           'soil_temp_L1_C', 'soil_temp_L2_C', 'soil_temp_L3_C',\n","           'soil_temp_L4_C', 'temp_C', 'precipitation_era5_mm',\n","           'wind_northward_m_s', 'soil_water_L2_fraction',\n","           'soil_water_L4_fraction', 'precipitation_chirps_mm']\n","\n","\n","cat_var = []\n","\n","y = df['yield_usda_1000ha']\n","\n","X = df[cat_var + num_var]\n","y = pd.DataFrame(y, columns=['yield_usda_1000ha'])"]},{"cell_type":"code","execution_count":null,"id":"b789c76b","metadata":{"id":"b789c76b"},"outputs":[],"source":["X.info()"]},{"cell_type":"code","execution_count":null,"id":"735dd4f7","metadata":{"id":"735dd4f7"},"outputs":[],"source":["# Train-test split:\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42 , shuffle=True)\n","\n","print(f\"X_train.shape: {X_train.shape}\")\n","print(f\"X_test.shape: {X_test.shape}\")\n","print(f\"y_train.shape: {y_train.shape}\")\n","print(f\"y_test.shape: {y_test.shape}\")"]},{"cell_type":"code","execution_count":null,"id":"399bfd01","metadata":{"id":"399bfd01"},"outputs":[],"source":["# Preprocessing with pipelines\n","\n","from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n","\n","\n","pipeline_categorical = Pipeline([('onehot', OneHotEncoder(handle_unknown=\"ignore\")),])\n","\n","pipeline_numerical = Pipeline([('scaler', MinMaxScaler(feature_range=(0,1))),])\n","\n","pipeline_full = ColumnTransformer([(\"categorical\", pipeline_categorical, cat_var),\n","                                   (\"numerical\", pipeline_numerical, num_var)])"]},{"cell_type":"code","execution_count":null,"id":"146d4516","metadata":{"id":"146d4516"},"outputs":[],"source":["# Apply the pipeline\n","\n","pipeline_full.fit(X_train)\n","\n","X_train_transformed = pipeline_full.transform(X_train)\n","X_test_transformed = pipeline_full.transform(X_test)\n","\n","print(f\"X_train_transformed.shape: {X_train_transformed.shape}\")\n","print(f\"X_test_transformed.shape: {X_test_transformed.shape}\")\n","print()\n","print('X_train_transformed:', type(X_train_transformed))\n","print('X_test_transformed:', type(X_test_transformed))"]},{"cell_type":"code","execution_count":null,"id":"79afcce5","metadata":{"id":"79afcce5"},"outputs":[],"source":["models = {\n","    'LinearRegression': LinearRegression(),\n","    'LassoRegressor': Lasso(max_iter=10000, random_state=42),\n","    'RidgeRegressor': Ridge(max_iter=10000, random_state=42),\n","    \"ElasticNet\": ElasticNet(alpha=0.02, random_state=42),\n","    # \"KNN\": KNeighborsRegressor(),\n","    'DTR': DecisionTreeRegressor(random_state=42),\n","    'SVR': SVR(),\n","    'RFR': RandomForestRegressor(random_state=42),\n","    \"ExtraTrees\": ExtraTreesRegressor(n_estimators=5, random_state=42),\n","    'ADABoost': AdaBoostRegressor(random_state=42),\n","    'XGBoost': xgb.XGBRegressor(random_state=42),\n","    'CatBoost': CatBoostRegressor(random_state=42),\n","    'LightGBM': lgb.LGBMRegressor(random_state=42)\n","}"]},{"cell_type":"code","execution_count":null,"id":"cf48bbaf","metadata":{"id":"cf48bbaf","scrolled":false},"outputs":[],"source":["# Train multiple models\n","\n","model_list=[]\n","r2_list=[]\n","mae_list=[]\n","mse_list=[]\n","rmse_list=[]\n","\n","for i in range(len(list(models))):\n","    model=list(models.values())[i]\n","    model.fit(X_train_transformed,y_train)\n","\n","    #Make Predictions\n","    y_pred=model.predict(X_test_transformed)\n","\n","    # Evaluation Metric:\n","    #r2 = model.score(X_test_transformed, y_test)\n","    r2 = r2_score(y_test, y_pred)\n","    mae = mean_absolute_error(y_test, y_pred)\n","    mse = mean_squared_error(y_test, y_pred)\n","    rmse= np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    model_list.append(list(models.keys())[i])\n","    r2_list.append(r2)\n","    mae_list.append(mae)\n","    mse_list.append(mse)\n","    rmse_list.append(rmse)\n","\n","    # Print the performance metrics for each model\n","    print(f\"Model: {list(models.keys())[i]}\")\n","    print(f\"R2 Score: {r2}\")\n","    print(f\"MAE: {mae}\")\n","    print(f\"MSE: {mse}\")\n","    print(f\"RMSE: {rmse}\")\n","    print(\"=\"*30)"]},{"cell_type":"code","execution_count":null,"id":"edbf1324","metadata":{"id":"edbf1324"},"outputs":[],"source":["# Find the index of the model with the best r2 score\n","best_index_r2 = r2_list.index(max(r2_list))\n","\n","# Find the index of the model with the best mae score\n","best_index_mae = mae_list.index(min(mae_list))\n","\n","# Find the index of the model with the best mse score\n","best_index_mse = mse_list.index(min(mse_list))\n","\n","# Find the index of the model with the best rmse score\n","best_index_rmse = rmse_list.index(min(rmse_list))\n","\n","# Determine the model with the best performance based on the chosen metric\n","best_r2_model = model_list[best_index_r2]\n","best_mae_model = model_list[best_index_mae]\n","best_mse_model = model_list[best_index_mse]\n","best_rmse_model = model_list[best_index_rmse]\n","\n","# Print the best models and their corresponding metric\n","print(\"The model with the best R2 score is:\", best_r2_model)\n","print(\"R2 score:\", r2_list[best_index_r2])\n","print(\"=\"*40)\n","print(\"The model with the best MAE score is:\", best_mae_model)\n","print(\"MAE:\", mae_list[best_index_mae])\n","print(\"=\"*40)\n","print(\"The model with the best MSE score is:\", best_mse_model)\n","print(\"MSE:\", mse_list[best_index_mse])\n","print(\"=\"*40)\n","print(\"The model with the best RMSE score is:\", best_rmse_model)\n","print(\"RMSE:\", rmse_list[best_index_rmse])"]},{"cell_type":"code","execution_count":null,"id":"354bfedf","metadata":{"id":"354bfedf"},"outputs":[],"source":["# Create a DF for Result:\n","\n","results_df = pd.DataFrame({\n","    'Model': model_list,\n","    'R2 Score': r2_list,\n","    'MAE': mae_list,\n","    'MSE': mse_list,\n","    'RMSE': rmse_list})\n","\n","results_df.sort_values(by=\"RMSE\", ascending=True)"]},{"cell_type":"markdown","id":"d9fc06af","metadata":{"id":"d9fc06af"},"source":["# Second Top Model: Ridge Regressor"]},{"cell_type":"markdown","id":"6d44a402","metadata":{"id":"6d44a402"},"source":["**Hyperparameter Search for Ridge Regression:**"]},{"cell_type":"code","execution_count":null,"id":"4d64007e","metadata":{"id":"4d64007e"},"outputs":[],"source":["# Hyperparameter Search for Ridge Regression:\n","\n","from sklearn.linear_model import Ridge\n","from sklearn.model_selection import GridSearchCV\n","\n","param_grid = {\n","    'alpha': [0.01, 0.1, 1.0, 10.0],\n","    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']}\n","\n","grid_search = GridSearchCV(\n","    estimator=Ridge(),\n","    param_grid=param_grid,\n","    scoring='neg_mean_squared_error',\n","    cv=5, n_jobs=-1, verbose=1)\n","\n","grid_search.fit(X_train_transformed, y_train)\n"]},{"cell_type":"code","execution_count":null,"id":"d4d76caf","metadata":{"id":"d4d76caf"},"outputs":[],"source":["print(grid_search.best_params_)\n","print(\"\\n\",grid_search.best_estimator_)"]},{"cell_type":"code","execution_count":null,"id":"faeac3c3","metadata":{"id":"faeac3c3"},"outputs":[],"source":["Tuned_Ridge_Reg = grid_search.best_estimator_\n","Tuned_Ridge_Reg"]},{"cell_type":"code","execution_count":null,"id":"a2e362c8","metadata":{"id":"a2e362c8"},"outputs":[],"source":["Tuned_Ridge_Reg .fit(X_train_transformed,y_train)\n","y_pred=Tuned_Ridge_Reg.predict(X_test_transformed)"]},{"cell_type":"code","execution_count":null,"id":"96c09910","metadata":{"id":"96c09910"},"outputs":[],"source":["from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n","\n","r2 = r2_score(y_test, y_pred)\n","mae = mean_absolute_error(y_test, y_pred)\n","mse = mean_squared_error(y_test, y_pred)\n","rmse = np.sqrt(mse)\n","\n","print(f\"R2 Score: {r2}\")\n","print(f\"MAE: {mse}\")\n","print(f\"MSE: {mae}\")\n","print(f\"RMSE: {rmse}\")"]},{"cell_type":"code","execution_count":null,"id":"f94d1385","metadata":{"id":"f94d1385","scrolled":false},"outputs":[],"source":["# Calculate residuals\n","residuals = y_test.values.flatten() - y_pred.flatten()\n","\n","# Visualize residuals\n","#sns.kdeplot(residuals)\n","sns.histplot(residuals, kde=True)\n","plt.title('Distribution of Residuals - Tuned Ridge Regression')\n","plt.xlabel('Residuals')\n","plt.ylabel('Density')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"f48a9a09","metadata":{"id":"f48a9a09","scrolled":false},"outputs":[],"source":["# Line Plot: Actual vs Predicted Values\n","\n","plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--', color='green', label='Actual')\n","plt.scatter(y_test, y_pred, label='Tuned Ridge Regression Predictions')\n","plt.xlabel('Actual Values')\n","plt.ylabel('Predicted Values')\n","plt.title('Actual vs Predicted Values - Tuned Ridge Regression')\n","plt.show()"]},{"cell_type":"markdown","id":"b1ae0917","metadata":{"id":"b1ae0917"},"source":["**Ploting the Learning Curve**"]},{"cell_type":"code","execution_count":null,"id":"89911d8a","metadata":{"scrolled":false,"id":"89911d8a"},"outputs":[],"source":["# Ploting the learning curve:\n","\n","from sklearn.model_selection import learning_curve\n","train_sizes, train_scores, test_scores = learning_curve(estimator=Tuned_Ridge_Reg,\n","                                                       X=X_train_transformed, y=y_train,\n","                                                       cv=5, train_sizes=np.linspace(0.1, 1.0, 20), n_jobs=-1)\n","\n","plt.figure(figsize=(8,4))\n","# Calculate training and test mean and std\n","\n","train_mean = np.mean(train_scores, axis=1)\n","train_std = np.std(train_scores, axis=1)\n","test_mean = np.mean(test_scores, axis=1)\n","test_std = np.std(test_scores, axis=1)\n","\n","# Plot the learning curve\n","\n","plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='Training Score')\n","plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n","\n","plt.plot(train_sizes, test_mean, color='green', marker='o', markersize=5, label='Cross-Validation Score')\n","plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n","\n","plt.title('Tuned Ridge Regression Learning Curve ')\n","plt.xlabel('Training Example', fontsize=12)\n","plt.ylabel('Accuracy Score', fontsize=12)\n","\n","plt.legend(loc='lower center', fontsize=8)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"4adf07fe","metadata":{"id":"4adf07fe"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"441b7238","metadata":{"id":"441b7238"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"22924bbf","metadata":{"id":"22924bbf"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"f3dbbc64","metadata":{"id":"f3dbbc64"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":5}